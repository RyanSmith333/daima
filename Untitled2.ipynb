{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18a222a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请选择你要进行的操作：\n",
      "1. 训练模型\n",
      "2. 测试模型\n",
      "1\n",
      "请输入wav文件的路径：\n",
      "E:\\1RS\\模型\\wave\n",
      "请输入xml文件的路径：\n",
      "E:\\1RS\\模型\\musicxml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryans\\AppData\\Local\\Temp\\ipykernel_9660\\63067878.py:145: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  notes, tags = xml_to_notes_and_tags(xml_file) # 将xml文件转换为音符序列和乐谱信息标签\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'C:G2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 207\u001b[0m\n\u001b[0;32m    205\u001b[0m     xml_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(xml_path, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(xml_path) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.musicxml\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m# 调用训练模型的函数\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m     train_model(wav_files, xml_files)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# 如果选择测试模型\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# 询问用户输入wav文件的文件名\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     wav_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m请输入wav文件的文件名：\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 155\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(wav_files, xml_files)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(wav_files, xml_files):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# 加载数据集\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m load_data(wav_files, xml_files)\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n",
      "Cell \u001b[1;32mIn[15], line 145\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(wav_files, xml_files)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wav_file, xml_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(wav_files, xml_files): \u001b[38;5;66;03m# 遍历每一对wav和xml文件\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     mel \u001b[38;5;241m=\u001b[39m wav_to_mel(wav_file) \u001b[38;5;66;03m# 将wav文件转换为梅尔频谱特征\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     notes, tags \u001b[38;5;241m=\u001b[39m xml_to_notes_and_tags(xml_file) \u001b[38;5;66;03m# 将xml文件转换为音符序列和乐谱信息标签\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mappend(mel) \u001b[38;5;66;03m# 将特征添加到输入列表中\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(tags) \u001b[38;5;66;03m# 将标签添加到输出列表中\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 105\u001b[0m, in \u001b[0;36mxml_to_notes_and_tags\u001b[1;34m(xml_file)\u001b[0m\n\u001b[0;32m    103\u001b[0m notes \u001b[38;5;241m=\u001b[39m [(pitch, \u001b[38;5;28mfloat\u001b[39m(duration)) \u001b[38;5;28;01mfor\u001b[39;00m pitch, duration \u001b[38;5;129;01min\u001b[39;00m notes] \u001b[38;5;66;03m# 将时值转换为浮点数\u001b[39;00m\n\u001b[0;32m    104\u001b[0m notes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(notes) \u001b[38;5;66;03m# 将音符列表转换为张量\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m ttags \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tag\u001b[38;5;241m.\u001b[39msplit()]) \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;66;03m# 将标签字符串转换为张量\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m notes, tags\n",
      "Cell \u001b[1;32mIn[15], line 105\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    103\u001b[0m notes \u001b[38;5;241m=\u001b[39m [(pitch, \u001b[38;5;28mfloat\u001b[39m(duration)) \u001b[38;5;28;01mfor\u001b[39;00m pitch, duration \u001b[38;5;129;01min\u001b[39;00m notes] \u001b[38;5;66;03m# 将时值转换为浮点数\u001b[39;00m\n\u001b[0;32m    104\u001b[0m notes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(notes) \u001b[38;5;66;03m# 将音符列表转换为张量\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m ttags \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tag\u001b[38;5;241m.\u001b[39msplit()]) \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;66;03m# 将标签字符串转换为张量\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m notes, tags\n",
      "Cell \u001b[1;32mIn[15], line 105\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    103\u001b[0m notes \u001b[38;5;241m=\u001b[39m [(pitch, \u001b[38;5;28mfloat\u001b[39m(duration)) \u001b[38;5;28;01mfor\u001b[39;00m pitch, duration \u001b[38;5;129;01min\u001b[39;00m notes] \u001b[38;5;66;03m# 将时值转换为浮点数\u001b[39;00m\n\u001b[0;32m    104\u001b[0m notes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(notes) \u001b[38;5;66;03m# 将音符列表转换为张量\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m ttags \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tag\u001b[38;5;241m.\u001b[39msplit()]) \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;66;03m# 将标签字符串转换为张量\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m notes, tags\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'C:G2'"
     ]
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "import music21\n",
    "import wave # 导入 wave 模块\n",
    "import numpy as np # 导入 numpy 模块\n",
    "\n",
    "# 定义神经网络模型\n",
    "class MusicModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MusicModel, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True) # 只使用一个循环层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x) # 循环层的输出就是音符序列和乐谱信息标签\n",
    "        return x\n",
    "\n",
    "# 定义一些超参数\n",
    "input_size = 128 # 梅尔频谱特征的维度\n",
    "hidden_size = 128 # 隐藏层的维度（和输出层的维度相同）\n",
    "batch_size = 32 # 批量大小\n",
    "num_epochs = 10 # 训练轮数\n",
    "learning_rate = 0.001 # 学习率\n",
    "\n",
    "# 创建模型实例，并定义损失函数和优化器\n",
    "model = MusicModel(input_size, hidden_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 定义一个函数，用于将wav文件转换为梅尔频谱特征\n",
    "def wav_to_mel(wav_file):\n",
    "    # 打开 wav 文件\n",
    "    wf = wave.open(wav_file, 'rb')\n",
    "    # 获取采样率\n",
    "    sr = wf.getframerate()\n",
    "    # 获取数据的字节数\n",
    "    nbytes = wf.getsampwidth()\n",
    "    # 获取数据的帧数\n",
    "    nframes = wf.getnframes()\n",
    "    # 读取所有的数据\n",
    "    data = wf.readframes(nframes)\n",
    "    # 关闭 wav 文件\n",
    "    wf.close()\n",
    "    # 将 data 转换为 numpy 数组\n",
    "    # 获取 data 的字节大小\n",
    "    data_size = len(data)\n",
    "    # 获取 np.float32 的字节大小\n",
    "    dtype_size = np.dtype(np.float32).itemsize\n",
    "    # 计算 data 的字节大小和 np.float32 的字节大小的余数\n",
    "    remainder = data_size % dtype_size\n",
    "    # 如果余数不为0，说明 data 的字节大小和 np.float32 的字节大小不是整数倍关系\n",
    "    if remainder != 0:\n",
    "        # 将 data 的字节大小减去余数，使其成为整数倍关系\n",
    "        data = data[:-remainder]\n",
    "    # 将 data 转换为 numpy 数组，指定数据类型为 np.float32\n",
    "    y = np.frombuffer(data, dtype=np.float32)\n",
    "    # 根据 nbytes 的值，选择合适的数据类型\n",
    "    if nbytes == 2:\n",
    "        y = y.astype(np.float32) # 这里改为 np.float32，而不是 np.int16\n",
    "    elif nbytes == 4:\n",
    "        y = y.astype(np.float32) # 这里不需要改变数据类型\n",
    "    # 检查 y 中是否有无穷大或者非数字的值\n",
    "    if not np.isfinite(y).all():\n",
    "        # 将无穷大或者非数字的值替换为有限的值\n",
    "        y = np.nan_to_num(y)\n",
    "    # 提取梅尔频谱特征\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr) # 这里用关键字参数，而不是位置参数\n",
    "    # 将功率谱转换为分贝值\n",
    "    mel = librosa.power_to_db(mel)\n",
    "    # 将numpy数组转换为张量\n",
    "    mel = torch.from_numpy(mel).float()\n",
    "    return mel\n",
    "\n",
    "# 定义一个函数，用于将musicxml文件转换为音符序列和乐谱信息标签\n",
    "def xml_to_notes_and_tags(xml_file):\n",
    "    score = music21.converter.parse(xml_file) # 加载musicxml文件\n",
    "    notes = [] # 存储音符序列的列表\n",
    "    tags = [] # 存储乐谱信息标签的列表\n",
    "    key = None # 存储当前的调号\n",
    "    clef = None # 存储当前的谱号\n",
    "    time = None # 存储当前的拍号\n",
    "    tempo = None # 存储当前的拍速\n",
    "    for element in score.flat: # 遍历乐谱中的所有元素\n",
    "        if isinstance(element, music21.key.Key): # 如果是调号，就更新当前的调号，并添加到标签列表中\n",
    "            key = element\n",
    "            tags.append(f\"K:{key.tonic.name}{key.mode}\")\n",
    "        elif isinstance(element, music21.clef.Clef): # 如果是谱号，就更新当前的谱号，并添加到标签列表中\n",
    "            clef = element\n",
    "            tags.append(f\"C:{clef.sign}{clef.line}\")\n",
    "        elif isinstance(element, music21.meter.TimeSignature): # 如果是拍号，就更新当前的拍号，并添加到标签列表中\n",
    "            time = element\n",
    "            tags.append(f\"T:{time.ratioString}\")\n",
    "        elif isinstance(element, music21.tempo.MetronomeMark): # 如果是拍速，就更新当前的拍速，并添加到标签列表中\n",
    "            tempo = element\n",
    "            tags.append(f\"M:{tempo.number}\")\n",
    "        elif isinstance(element, music21.note.Note): # 如果是音符，就获取其音高和时值，并添加到音符列表中\n",
    "            pitch = element.pitch.midi # 音高（以MIDI数字表示）\n",
    "            duration = element.duration.quarterLength # 时值（以四分音符为单位）\n",
    "            notes.append((pitch, duration))\n",
    "    notes = [(pitch, float(duration)) for pitch, duration in notes] # 将时值转换为浮点数\n",
    "    notes = torch.tensor(notes) # 将音符列表转换为张量\n",
    "    ttags = [torch.tensor([int(x) for x in tag.split()]) for tag in tags] # 将标签字符串转换为张量\n",
    "    return notes, tags # 返回音符序列和乐谱信息标签\n",
    "\n",
    "# 定义一个函数，用于将音符序列和乐谱信息标签一起转换为musicxml文件\n",
    "def notes_and_tags_to_xml(notes, tags, xml_file):\n",
    "    score = music21.stream.Score() # 创建一个空的乐谱对象\n",
    "    part = music21.stream.Part() # 创建一个空的声部对象\n",
    "    i = 0 # 标签序列的索引\n",
    "    for note in notes: # 遍历音符序列中的每个音符\n",
    "        pitch = note[0] # 获取音高\n",
    "        duration = note[1] # 获取时值\n",
    "        n = music21.note.Note() # 创建一个音符对象\n",
    "        n.pitch.midi = pitch # 设置音高\n",
    "        n.duration.quarterLength = duration # 设置时值\n",
    "        if i < len(tags): # 如果还有标签，就检查是否需要添加乐谱信息\n",
    "            tag = tags[i] # 获取当前的标签\n",
    "            if tag.startswith(\"K:\"): # 如果是调号，就创建一个调号对象，并添加到声部中\n",
    "                key = music21.key.Key(tag[2:])\n",
    "                part.append(key)\n",
    "            elif tag.startswith(\"C:\"): # 如果是谱号，就创建一个谱号对象，并添加到声部中\n",
    "                clef = music21.clef.Clef(tag[2:])\n",
    "                part.append(clef)\n",
    "            elif tag.startswith(\"T:\"): # 如果是拍号，就创建一个拍号对象，并添加到声部中\n",
    "                time = music21.meter.TimeSignature(tag[2:])\n",
    "                part.append(time)\n",
    "            elif tag.startswith(\"M:\"): # 如果是拍速，就创建一个拍速对象，并添加到声部中\n",
    "                tempo = music21.tempo.MetronomeMark(number=int(tag[2:]))\n",
    "                part.append(tempo)\n",
    "            i += 1 # 更新标签序列的索引\n",
    "        part.append(n) # 将音符添加到声部中\n",
    "    score.append(part) # 将声部添加到乐谱中\n",
    "    score.write('musicxml', xml_file) # 将乐谱写入musicxml文件 # 将乐谱写入musicxml文件，并返回文件名\n",
    "    return xml_file\n",
    "\n",
    "# 定义一个函数，用于加载数据集\n",
    "def load_data(wav_files, xml_files):\n",
    "    inputs = [] # 存储输入特征的列表\n",
    "    outputs = [] # 存储输出标签的列表\n",
    "    for wav_file, xml_file in zip(wav_files, xml_files): # 遍历每一对wav和xml文件\n",
    "        mel = wav_to_mel(wav_file) # 将wav文件转换为梅尔频谱特征\n",
    "        notes, tags = xml_to_notes_and_tags(xml_file) # 将xml文件转换为音符序列和乐谱信息标签\n",
    "        inputs.append(mel) # 将特征添加到输入列表中\n",
    "        outputs.append(tags) # 将标签添加到输出列表中\n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True) # 对输入特征进行填充，使其具有相同的长度\n",
    "    outputs = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True) # 对输出标签进行填充，使其具有相同的长度\n",
    "    return inputs, outputs # 返回输入特征和输出标签\n",
    "\n",
    "# 定义一个函数，用于训练模型\n",
    "def train_model(wav_files, xml_files):\n",
    "    # 加载数据集\n",
    "    inputs, outputs = load_data(wav_files, xml_files)\n",
    "    # 训练模型\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i in range(0, len(inputs), batch_size):\n",
    "            x = inputs[i:i+batch_size]\n",
    "            y = outputs[i:i+batch_size]\n",
    "            y_pred = model(x) # 循环层的输出就是音符序列和乐谱信息标签\n",
    "            y_pred = y_pred.reshape(-1, hidden_size) # 将预测值展平为二维张量\n",
    "            y = y.reshape(-1) # 将标签展平为一维张量\n",
    "            loss = criterion(y_pred, y) # 计算交叉熵损失\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "    # 保存模型\n",
    "    torch.save(model, \"model.pth\")\n",
    "    print(\"模型训练完成，已保存为model.pth\")\n",
    "# 定义一个函数，用于测试模型\n",
    "def test_model(wav_file, xml_file):\n",
    "    # 加载模型\n",
    "    model = torch.load(\"model.pth\")\n",
    "    # 将wav文件转换为梅尔频谱特征\n",
    "    mel = wav_to_mel(wav_file)\n",
    "    mel = mel.unsqueeze(0)\n",
    "    # 通过模型得到音符序列和乐谱信息标签\n",
    "    y_pred = model(mel)\n",
    "    # 循环层的输出就是音符序列和乐谱信息标签\n",
    "    y_pred = y_pred.squeeze(0)  # 在批次维度上去掉一个维度\n",
    "    notes = y_pred[:, :output_size]  # 取前output_size列作为音符序列\n",
    "    tags = y_pred[:, output_size:]  # 取后num_tags列作为乐谱信息标签\n",
    "    notes = notes.argmax(1)  # 取每一行的最大值作为音符序列的标签（这里假设输出是one-hot编码的）\n",
    "    tags = tags.argmax(1)  # 取每一行的最大值作为乐谱信息标签的标签（这里假设输出是one-hot编码的）\n",
    "    # 将音符序列和标签序列转换为musicxml文件，并保存到指定的文件名\n",
    "    notes_and_tags_to_xml(notes, tags, xml_file)\n",
    "    print(f\"音乐生成完成，已保存为{xml_file}\")\n",
    "\n",
    "# 运行程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 询问用户是要训练模型还是测试模型\n",
    "    mode = input(\"请选择你要进行的操作：\\n1. 训练模型\\n2. 测试模型\\n\")\n",
    "    if mode == \"1\":\n",
    "        # 如果选择训练模型\n",
    "        # 询问用户输入wav文件的路径\n",
    "        wav_path = input(\"请输入wav文件的路径：\\n\")\n",
    "        # 询问用户输入xml文件的路径\n",
    "        xml_path = input(\"请输入xml文件的路径：\\n\")\n",
    "        # 获取wav文件和xml文件的列表\n",
    "        wav_files = [os.path.join(wav_path, f) for f in os.listdir(wav_path) if f.endswith(\".wav\")]\n",
    "        xml_files = [os.path.join(xml_path, f) for f in os.listdir(xml_path) if f.endswith(\".musicxml\")]\n",
    "        # 调用训练模型的函数\n",
    "        train_model(wav_files, xml_files)\n",
    "    elif mode == \"2\":\n",
    "        # 如果选择测试模型\n",
    "        # 询问用户输入wav文件的文件名\n",
    "        wav_file = input(\"请输入wav文件的文件名：\\n\")\n",
    "        # 询问用户输入xml文件的文件名\n",
    "        xml_file = input(\"请输入xml文件的文件名：\\n\")\n",
    "        # 调用测试模型的函数\n",
    "        test_model(wav_file, xml_file)\n",
    "    else:\n",
    "        # 如果选择其他选项\n",
    "        # 提示用户输入无效\n",
    "        print(\"输入无效，请重新运行程序。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64089599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
